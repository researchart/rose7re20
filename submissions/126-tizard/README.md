# 126 - Voice of the Users: A Demographic Study of Software Feedback Behaviour

Our submitted paper (#126) presents the results of a survey of 1040 software users on their feedback giving habits.
The goal of the study is to discover which software users give online written feedback to app stores, product forums and social media.

### Our Artifact
The submitted artifact is the survey our paper is based on (pdf format), consisting of 24 questions with answer options.
With the submitted document the study detailed in our paper can be repeated and its findings evaluated.

### Availability
The survey document (pdf) has been made available on Zenodo -> https://zenodo.org/record/3674076#%23.XkxNFygzZPY

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3674076.svg)](https://doi.org/10.5281/zenodo.3674076)

## Study Overview

### Study Objective
Paper link: (TBC)

Online user feedback about software products has been given a lot of focus in recent requirements engineering research. However, only a subset of software users give online feedback, therefore we should ask, how representative is this feedback?
In this study we directly survey software users to understand which demographics write online feedback and what motivates them to do so. 

### Study Design
The survey consists of 24 multiple-choice questions. The survey consisted of five main sets of questions. The first three sets of questions asked about the feedback the participant provides in the three feedback channels under investigation: app stores (Q1-5), social media (Q6-9), and product forums (Q10-13). 
The remaining two sets of questions collect software usage information (Q15-18) and demographic information (Q19-24). Descriptions of what was meant by app store and product forum feedback were given within the survey to help participants understand the question context. Questions eliciting details on feedback habits were asked before software usage and demographic questions to highlight the propose of the study and to maintain participant interest. 

### Ethical Approval
The survey had ethics approval from the University of Auckland's Human Participants Ethics Committee.

### Recruitment, Data Collection and Analysis  

*Note: The methodology described below was used in our study and are not necessarily required for reuse of the survey.*

To recruit participants, convenience sampling was used. This was chosen as the best method to engage a good number of survey participants in a reasonable time period. The survey was primarily made available online through the Qualtics survey platform. 

To answer our research questions, we analysed the ratio of respondents in each user group (based on demographics or software usage) that  reported a particular behaviour, e.g. giving feedback on a particular feedback channel or having a certain motivation. Chi-squared tests, which tests for differences in proportion between two groups, were used to find if differences in reported behaviours between user groups are statistically significant.





